{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca50fb6-ca16-4e25-9f1a-4459ca9f1820",
   "metadata": {},
   "source": [
    "# Prediction of the Success of Bank Telemarketing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5baf6-4fcc-4df4-80d6-1cc2c8211cfe",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## Team Paramount\n",
    "  1. Penchala Akshay Kumar Kandagaddala - U3586552\n",
    "  2. Sri Kumar Dundigalla - U48489930\n",
    "  3. Shashank Rao Gujja - U62836356\n",
    "  4. Yeshwant Reddy Kesari - U59107089\n",
    "  5. Nagulapalli Venkata Satya Naveen - U80765768\n",
    "  6. Kushal Reddy Rededdy - U09758182 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592c0ea8-3f08-4087-a43b-61d1d963a7f6",
   "metadata": {},
   "source": [
    "# Bussiness Problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38366d03-a058-49c5-9d32-468d37d99e7a",
   "metadata": {},
   "source": [
    "#### Marketing team in a bank is one of the core teams for the upliftment of the organization. They will create a lot of impact on the development of the bank and the first step of the growth in any bank will be started by the marketing team.\n",
    "\n",
    "#### Marketing is the process of presenting a product or service to the market, promoting it, and encouraging consumers to make purchases. The key to a successful business nowadays is effective marketing, and marketing profoundly affects our day-to-day lives. \n",
    "\n",
    "#### The data refers to direct marketing initiatives carried out by a bank in Portugal, the marketing initiatives were centered on phone calls, it was occasionally essential to have many conversations with the same client to ascertain if the product bank term deposit would be subscribed (yes) or not (no)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d4d63-65c5-41c0-b5c6-fbbd8619a167",
   "metadata": {},
   "source": [
    "\n",
    "# Importing all Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55e9c94b-64ec-4e0d-ace2-6bb05c09abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as pltB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score ,f1_score,classification_report, make_scorer,recall_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc9735-615a-4b13-bab0-e925ba53e458",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aaee783-7788-4021-ab25-f2c5299d0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank.csv') #loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef5008-9243-46be-acfd-e508b9b49bdf",
   "metadata": {},
   "source": [
    "# Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78ef92d3-0331-4ac4-a37f-65295f82acbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # checking first 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cd21c75-25b2-4229-8b6a-d703ac1a9239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 17)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # checking number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64d8adb9-6ad5-43d6-a141-00c8abd7761c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
       "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns #chcecking column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bad93b4-29e7-439d-ad66-f1839fbc1171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.936210</td>\n",
       "      <td>1362.272058</td>\n",
       "      <td>15.806419</td>\n",
       "      <td>258.163080</td>\n",
       "      <td>2.763841</td>\n",
       "      <td>40.197828</td>\n",
       "      <td>0.580323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.618762</td>\n",
       "      <td>3044.765829</td>\n",
       "      <td>8.322476</td>\n",
       "      <td>257.527812</td>\n",
       "      <td>3.098021</td>\n",
       "      <td>100.128746</td>\n",
       "      <td>2.303441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>-8019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>102127.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>275.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        balance           day      duration      campaign  \\\n",
       "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
       "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
       "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
       "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
       "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
       "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
       "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
       "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
       "\n",
       "              pdays      previous  \n",
       "count  45211.000000  45211.000000  \n",
       "mean      40.197828      0.580323  \n",
       "std      100.128746      2.303441  \n",
       "min       -1.000000      0.000000  \n",
       "25%       -1.000000      0.000000  \n",
       "50%       -1.000000      0.000000  \n",
       "75%       -1.000000      0.000000  \n",
       "max      871.000000    275.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() #Statistical Summary of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddbcfe73-ec21-4a02-a0a8-64500390b575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() #information abour data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd83a92-1ff5-44e7-b53e-994684bb55b9",
   "metadata": {},
   "source": [
    "# Cleaning the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2af798fc-8431-45ba-9063-734e6ba21b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [s.strip().replace(' ', '_') for s in df.columns] #replacing colums names which has spaces with the \"_\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92df50-ca18-4327-b96f-27cfa5a06666",
   "metadata": {},
   "source": [
    "#### We have changed the coloumn names here in a more readable and reliable way by adding an underscore in between the spaces. This will be more lookable and ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2873095-3490-4369-ae52-1934d7a0b68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #Checking for null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be52ba92-4736-4d95-ba3a-16684121eb80",
   "metadata": {},
   "source": [
    "#### From the above output, we could see that We do not have any NA values in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97f2128b-b449-4a52-a864-f026830a1b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "job          object\n",
       "marital      object\n",
       "education    object\n",
       "default      object\n",
       "balance       int64\n",
       "housing      object\n",
       "loan         object\n",
       "contact      object\n",
       "day           int64\n",
       "month        object\n",
       "duration      int64\n",
       "campaign      int64\n",
       "pdays         int64\n",
       "previous      int64\n",
       "poutcome     object\n",
       "y            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc445e-26c8-47f1-a186-718124ac1382",
   "metadata": {},
   "source": [
    "# Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a106949b-d48d-4836-a31e-3950cec3c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Category_Features=['job','marital','education','default','housing','loan','contact','month','poutcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2195f68c-18b9-4c90-9eb9-c166b67c985c",
   "metadata": {},
   "source": [
    "#### We are grouping all the object type variables into a list here to change their datatype to category which is feasible to find the relationship between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1565fb9-a74c-44db-862f-4e82a23f4d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age             int64\n",
       "job          category\n",
       "marital      category\n",
       "education    category\n",
       "default      category\n",
       "balance         int64\n",
       "housing      category\n",
       "loan         category\n",
       "contact      category\n",
       "day             int64\n",
       "month        category\n",
       "duration        int64\n",
       "campaign        int64\n",
       "pdays           int64\n",
       "previous        int64\n",
       "poutcome     category\n",
       "y            category\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lopping through every category.\n",
    "for i in Category_Features+['y']:\n",
    "    df[i] = df[i].astype('category') #Casting from object class to category class.\n",
    "df.dtypes #Cheching all columns Data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39c3c752-6ad0-4163-909c-578466cb7cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age             int64\n",
       "job           float64\n",
       "marital       float64\n",
       "education     float64\n",
       "default       float64\n",
       "balance         int64\n",
       "housing       float64\n",
       "loan          float64\n",
       "contact       float64\n",
       "day             int64\n",
       "month         float64\n",
       "duration        int64\n",
       "campaign        int64\n",
       "pdays           int64\n",
       "previous        int64\n",
       "poutcome      float64\n",
       "y            category\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OrdinalEncoder() #Creating instace of OrdinalEncoder.\n",
    "for i in Category_Features:\n",
    "    df[i]=enc.fit_transform(df[[i]]) #Coverting to numerical.\n",
    "df.dtypes #Cheching all columns Data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae924773-2840-40e9-b59b-d0fc8b2164c7",
   "metadata": {},
   "source": [
    "#### Here, we will perform the ordinal encoding on the predictor categorical variable to encode them to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "365ad96e-9097-4014-8201-8fbee1a02626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            int64\n",
       "job          float64\n",
       "marital      float64\n",
       "education    float64\n",
       "default      float64\n",
       "balance        int64\n",
       "housing      float64\n",
       "loan         float64\n",
       "contact      float64\n",
       "day            int64\n",
       "month        float64\n",
       "duration       int64\n",
       "campaign       int64\n",
       "pdays          int64\n",
       "previous       int64\n",
       "poutcome     float64\n",
       "y              int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'y'\n",
    "predictors = list(df.columns) #Assigning Predictors and coverting pandas series object to list.\n",
    "predictors.remove(target)\n",
    "#LableEncoding for target variable\n",
    "enc = LabelEncoder() \n",
    "df[target]=enc.fit_transform(df[target])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e8a3f-7786-4ca3-aea2-ef517ef9b2e5",
   "metadata": {},
   "source": [
    "#### Performing Label encoding on the target variables to turn the categorical variables to numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac056cc4-a4a3-4c3c-899e-4490359ac012",
   "metadata": {},
   "source": [
    "# Splitting the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82afd83e-fe23-4f57-9670-05810bf5a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[predictors]\n",
    "y=df[target]\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaad939-f1c9-4e09-a9b9-c86486345683",
   "metadata": {},
   "source": [
    "#### We are splitting the data into training and test here. The training takes 70% of the population data, whereas test takes the remaining 30%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a62abd-77ae-45e0-8024-a1cb6c76d283",
   "metadata": {},
   "source": [
    "# Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58e120a4-2d58-41d0-bc27-ee4621bceea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3738\n",
       "1    3738\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "undersample = NearMiss(version=1, n_neighbors=3)\n",
    "train_X, train_y = undersample.fit_resample(train_X, train_y)\n",
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b044c7-56ec-40a9-92ec-115fe99efe71",
   "metadata": {},
   "source": [
    "#### Since, the data is not balanced with respect to the target variable, we have performed the undersampling on the data to avoid the discrepancy between observations for the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7808141-1876-4f6c-8dfb-858f11ce3f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>320</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>320</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>310</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>190</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7471</th>\n",
       "      <td>25</td>\n",
       "      <td>-191</td>\n",
       "      <td>19</td>\n",
       "      <td>958</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7472</th>\n",
       "      <td>35</td>\n",
       "      <td>1162</td>\n",
       "      <td>30</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7473</th>\n",
       "      <td>32</td>\n",
       "      <td>1138</td>\n",
       "      <td>4</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>61</td>\n",
       "      <td>1853</td>\n",
       "      <td>10</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7475</th>\n",
       "      <td>60</td>\n",
       "      <td>17297</td>\n",
       "      <td>26</td>\n",
       "      <td>664</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7476 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  balance  day  duration  campaign  pdays  previous\n",
       "0      26        0    6       320         3     -1         0\n",
       "1      30        0    8       320         1     -1         0\n",
       "2      35        0    5       310         1     -1         0\n",
       "3      32        0   19       188         2     -1         0\n",
       "4      33        0   20       190         2     -1         0\n",
       "...   ...      ...  ...       ...       ...    ...       ...\n",
       "7471   25     -191   19       958         7     -1         0\n",
       "7472   35     1162   30       175         1     -1         0\n",
       "7473   32     1138    4       214         3     83         3\n",
       "7474   61     1853   10       520         1    181         2\n",
       "7475   60    17297   26       664        11     -1         0\n",
       "\n",
       "[7476 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in Category_Features: #Removing \n",
    "    predictors.remove(i)\n",
    "predictors #Checking Predictors list.\n",
    "train_X[predictors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9052e759-b04e-4832-8226-00fe941a547e",
   "metadata": {},
   "source": [
    "#  Standardzation of quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "faf2d893-94b8-49d9-a367-23328609a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_X[predictors])\n",
    "\n",
    "# Transform the predictors of training, validation and newCustomer\n",
    "train_scaled_data= scaler.transform(train_X[predictors])\n",
    "test_scaled_data = scaler.transform(test_X[predictors])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42f3eee3-7967-4da2-b13b-ca3be2d1e965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.228237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.350235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.131881</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.215488</td>\n",
       "      <td>0.361253</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>-0.318787</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.880235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.350235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.883172</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.215488</td>\n",
       "      <td>-0.653867</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>-0.318787</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.445232</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.350235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.256235</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.245237</td>\n",
       "      <td>-0.653867</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>-0.318787</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.706234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.350235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484726</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.608172</td>\n",
       "      <td>-0.146307</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>-0.318787</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.619233</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.350235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.609080</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.602223</td>\n",
       "      <td>-0.146307</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>-0.318787</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7471</th>\n",
       "      <td>-1.315238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.417122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.484726</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.682487</td>\n",
       "      <td>2.391493</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>-0.318787</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7472</th>\n",
       "      <td>-0.445232</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.852624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.646846</td>\n",
       "      <td>-0.653867</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>-0.318787</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7473</th>\n",
       "      <td>-0.706234</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.380590</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.530825</td>\n",
       "      <td>0.361253</td>\n",
       "      <td>0.544559</td>\n",
       "      <td>1.346658</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>1.816783</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.634463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.379488</td>\n",
       "      <td>-0.653867</td>\n",
       "      <td>1.625115</td>\n",
       "      <td>0.791509</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7475</th>\n",
       "      <td>1.729783</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.706999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.355206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.807871</td>\n",
       "      <td>4.421733</td>\n",
       "      <td>-0.381633</td>\n",
       "      <td>-0.318787</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7476 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age   job  marital  education  default   balance  housing  loan  \\\n",
       "0    -1.228237   1.0      1.0        1.0      0.0 -0.350235      1.0   0.0   \n",
       "1    -0.880235   1.0      0.0        1.0      0.0 -0.350235      0.0   1.0   \n",
       "2    -0.445232   4.0      1.0        2.0      0.0 -0.350235      1.0   0.0   \n",
       "3    -0.706234   1.0      1.0        1.0      0.0 -0.350235      1.0   0.0   \n",
       "4    -0.619233   4.0      2.0        1.0      0.0 -0.350235      0.0   0.0   \n",
       "...        ...   ...      ...        ...      ...       ...      ...   ...   \n",
       "7471 -1.315238   1.0      2.0        1.0      0.0 -0.417122      1.0   0.0   \n",
       "7472 -0.445232   4.0      2.0        2.0      0.0  0.056685      0.0   0.0   \n",
       "7473 -0.706234   8.0      2.0        2.0      0.0  0.048281      0.0   0.0   \n",
       "7474  1.816783   5.0      1.0        1.0      0.0  0.298667      0.0   0.0   \n",
       "7475  1.729783  11.0      1.0        3.0      0.0  5.706999      0.0   0.0   \n",
       "\n",
       "      contact       day  month  duration  campaign     pdays  previous  \\\n",
       "0         0.0 -1.131881    8.0 -0.215488  0.361253 -0.381633 -0.318787   \n",
       "1         0.0 -0.883172    5.0 -0.215488 -0.653867 -0.381633 -0.318787   \n",
       "2         0.0 -1.256235    8.0 -0.245237 -0.653867 -0.381633 -0.318787   \n",
       "3         0.0  0.484726    9.0 -0.608172 -0.146307 -0.381633 -0.318787   \n",
       "4         2.0  0.609080    8.0 -0.602223 -0.146307 -0.381633 -0.318787   \n",
       "...       ...       ...    ...       ...       ...       ...       ...   \n",
       "7471      2.0  0.484726    6.0  1.682487  2.391493 -0.381633 -0.318787   \n",
       "7472      0.0  1.852624    0.0 -0.646846 -0.653867 -0.381633 -0.318787   \n",
       "7473      0.0 -1.380590    8.0 -0.530825  0.361253  0.544559  1.346658   \n",
       "7474      1.0 -0.634463    1.0  0.379488 -0.653867  1.625115  0.791509   \n",
       "7475      0.0  1.355206    1.0  0.807871  4.421733 -0.381633 -0.318787   \n",
       "\n",
       "      poutcome  \n",
       "0          3.0  \n",
       "1          3.0  \n",
       "2          3.0  \n",
       "3          3.0  \n",
       "4          3.0  \n",
       "...        ...  \n",
       "7471       3.0  \n",
       "7472       3.0  \n",
       "7473       2.0  \n",
       "7474       2.0  \n",
       "7475       3.0  \n",
       "\n",
       "[7476 rows x 16 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=0\n",
    "for i in predictors:\n",
    "    train_X[i]=train_scaled_data[:,s]\n",
    "    test_X[i]=test_scaled_data[:,s]\n",
    "    s=s+1\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b3af1f6-aa1e-4dc2-aa1f-fafe73737a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithms = ['knn','knn','DecisionTree','DecisionTree','RandomForest','RandomForest','AdaBoostClassifier','AdaBoostClassifier','GradientBoosting','GradientBoosting','XGBClassifier','XGBClassifier','LogisticRegression','LogisticRegression']\n",
    "Recall_values =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28df7ae-c98e-4f7b-b718-2645b0fc9381",
   "metadata": {},
   "source": [
    "#### Since, continuous variables are measured in different scales we performed standardization to get them into the same scale. Here we have performed the same on train_predictors and validation_predictors. Firstly, we have removed our categorical variables and the target variable, because we should not perform standardization on them. Later, we will append those category features list to the standardized dataframe. Finally, we get a standardized dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c8e28b-4184-4836-8c72-32f43c0befc7",
   "metadata": {},
   "source": [
    "#### False Positive: The actual outcome was that the client did not subscribe to the product, but the model predicted that the customer would. The concern here is that the marketing team will target consumers that do not need to be targeted. The campaign team wastes time and effort, while the client is bombarded with advertisements that are unnecessary.\n",
    "\n",
    "#### False Negative: The actual outcome was that the client subscribed to the product, but the model predicted that the customer would not subscribe to the product. As a result, the bank will suffer a significant loss because they are missing one of their investors for the product.\n",
    "\n",
    "#### Here, FP is preferable over FN since we have less loss with false positive than with false negatives, thus we will concentrate on 'Recall'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8886e6bf-9af7-4e17-b586-cabfff41878d",
   "metadata": {},
   "source": [
    "# Prediction with K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1438a0a1-136b-43b8-95dd-3905b4fea137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters : Recall score:\n",
      "0.8079\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "_ = knn.fit(train_X, train_y)\n",
    "y_pred = knn.predict(test_X)\n",
    "print(f\"Using default parameters : Recall score:\\n{recall_score(test_y,y_pred):.4f}\")#Checking model Recall score.\n",
    "Recall_values.append(recall_score(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8414805-46e1-4b19-bd32-7a4a19084725",
   "metadata": {},
   "source": [
    "#### We have applied the K-nn model on our training dataset which is actually splitted from the original dataset and found the recall value to be 0.8079."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6b15c1c-a1bd-4eaf-9c81-b6277a813608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall score:  0.8111410589095497\n",
      "parameters:  {'metric': 'cosine', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "CPU times: total: 36.8 s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = 'recall'\n",
    "k_fold = 10\n",
    "# Start with an initial guess for parameters\n",
    "param_grid = {\n",
    "     'n_neighbors': list(range(1,round(np.sqrt(len(df))),2)),\n",
    "    'metric': ['euclidean', 'cosine','manhattan','minkowski'],\n",
    "    'weights':['uniform','distance']\n",
    "}\n",
    "best_grid_search_model = GridSearchCV(KNeighborsClassifier(), param_grid, cv=k_fold, scoring=score_measure,\n",
    "                          n_jobs=-1,error_score='raise')  # n_jobs=-1 will utilize all available CPUs \n",
    "_=best_grid_search_model.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', best_grid_search_model.best_score_)\n",
    "print('parameters: ', best_grid_search_model.best_params_)\n",
    "\n",
    "Best_recall_knn = best_grid_search_model.best_score_\n",
    "Recall_values.append(best_grid_search_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9636c-5b2c-4754-823b-48125cf746a4",
   "metadata": {},
   "source": [
    "#### From the above observations we can depict that the best value of k is found to be at k=3 with the recall of around 81% by using cosine metric. Where recall is improved when compared to before after performing k fold which means it has improved model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aad989d2-f445-477d-bfe6-9384cce000ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training set and the test set \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a05bf8b0-79b2-44b1-8c3a-639b0f9befcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3738\n",
       "1    3738\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "undersample = NearMiss(version=1, n_neighbors=3)\n",
    "train_X, train_y = undersample.fit_resample(train_X, train_y)\n",
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1b6a3-c642-43d7-9f3e-337254824da0",
   "metadata": {},
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0120b9ad-5c36-4b90-a251-dca3eec83dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters : Recall score:\n",
      "0.8839\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree \n",
    "dtree=DecisionTreeClassifier(random_state=3)\n",
    "_ = dtree.fit(train_X, train_y)\n",
    "y_pred = dtree.predict(test_X)\n",
    "print(f\"Using default parameters : Recall score:\\n{recall_score(test_y,y_pred):.4f}\")#Checking model Recall score.\n",
    "Recall_values.append(recall_score(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a75d2a1-c838-4fc4-9ebf-225df9cec39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5880 candidates, totalling 58800 fits\n",
      "recall score:  0.8927269859930325\n",
      "parameters:  {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 7, 'min_samples_split': 6}\n",
      "CPU times: total: 57.9 s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = 'recall'\n",
    "k_fold = 10\n",
    "\n",
    "param_grid = {\n",
    "\n",
    "    'criterion':  ['gini','entropy','log_loss'],\n",
    "    'max_depth':  [2]+list(range(5,50,5)),\n",
    "     'min_samples_leaf': range(2,len(train_X.columns),1) , \n",
    "     'min_samples_split': range(2,len(train_X.columns),1)\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "best_grid_search_model = GridSearchCV(estimator=DecisionTreeClassifier(),param_grid=param_grid,cv=k_fold, n_jobs=-1,verbose=1,scoring=score_measure)\n",
    "\n",
    "_ = best_grid_search_model.fit(train_X, train_y)\n",
    "\n",
    "print(score_measure, 'score: ', best_grid_search_model.best_score_)\n",
    "\n",
    "print('parameters: ', best_grid_search_model.best_params_)\n",
    "Best_recall_DT = best_grid_search_model.best_score_\n",
    "Recall_values.append(best_grid_search_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a262d7-4fcb-4053-b4f3-89f7123695a1",
   "metadata": {},
   "source": [
    "#### Here after performing the analysis on the splitted data, we were able to get the value of the performace metrics here and found that the recall is found to be around 88% for decision tree, and after performing k- fold it increased its recall rate from 88% to 89%. Eventhough this model took more time for computations than the above, this provided the best reult than the prior models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c263de83-fc6d-4528-b4e5-20b985dedf99",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3e0bcf8-9193-4e4b-bc92-afd5cd5e4630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters : Recall score:\n",
      "0.8994\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "rforest = RandomForestClassifier(random_state=1)\n",
    "_ = rforest.fit(train_X, train_y)\n",
    "y_pred = rforest.predict(test_X)\n",
    "print(f\"Using default parameters : Recall score:\\n{recall_score(test_y,y_pred):.4f}\")#Checking model Recall score.\n",
    "Recall_values.append(recall_score(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f225680f-d8cd-4a8c-9e0a-549d7ed5b16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "recall score:  0.9114500150535477\n",
      "parameters:  {'bootstrap': True, 'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 20}\n",
      "CPU times: total: 2.97 s\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dsksr\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = 'recall'\n",
    "k_fold = 10\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": range(20,60,20),\n",
    "    'max_features':['auto', 'sqrt'],\n",
    "     'min_samples_leaf': [1, 2, 4],\n",
    "     'min_samples_split': [2, 5, 10],\n",
    "    'max_depth': [20,40],\n",
    "    'bootstrap': [True],\n",
    "\n",
    "         }\n",
    "best_grid_search_model = GridSearchCV(estimator=RandomForestClassifier(random_state=1), \n",
    "                                    scoring=score_measure, param_grid=param_grid, cv=k_fold, verbose=1,  n_jobs = -1,error_score='raise')\n",
    "_ = best_grid_search_model.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', best_grid_search_model.best_score_)\n",
    "print('parameters: ', best_grid_search_model.best_params_)\n",
    "Best_recall_RF = best_grid_search_model.best_score_\n",
    "Recall_values.append(best_grid_search_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc63cc72-5423-4c75-9d34-b03023b18e26",
   "metadata": {},
   "source": [
    "#### We are performing random forest on the dataset to check for the further best results if possible.\n",
    "#### The Parameters that we have used here are :\n",
    "#### 1. bootstrap : It takes the values of either true or false. If true, it takes the splitted data to build each tree.\n",
    "#### 2. n_estimators : Number of trees we want to build before taking the maximum averages of predictions. Though, higher number of trees improves the performance, it will make the code to run slower. We have taken an ideal range of 20 to 100.\n",
    "#### 3. max_features : The maximum number of features Random Forest is allowed to try in individual tree.\n",
    "#### 4. max_depth : Here, we have considered the longest path between the root node and leaf node in a list.\n",
    "#### 5. min_samples_leaf : the bare minimum of samples that must be present at a leaf node.\n",
    "#### 6. min_samples_split : It is the minimum number of samples required to split an internal node.\n",
    "#### By calling the Random forest function setting all of these parameters, we could find the optimal model at the 'max_depth': 20, 'max_features': 0'max_samples': 0.5, 'n_estimators': 20 with an accuracy of 0.9114500150535477."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88118ec-a0d1-49aa-9217-e8d2407cd737",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a71073e-4816-41b0-8914-04f9fae886e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters : Recall score:\n",
      "0.8910\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#AdaBoostClassifier\n",
    "adaboost = AdaBoostClassifier(random_state=3)\n",
    "_ = adaboost.fit(train_X, train_y)\n",
    "y_pred = adaboost.predict(test_X)\n",
    "print(f\"Using default parameters : Recall score:\\n{recall_score(test_y,y_pred):.4f}\")#Checking model Recall score.\n",
    "Recall_values.append(recall_score(test_y,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7031498b-2e0c-4606-b12f-bb465ff75084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 196 candidates, totalling 1960 fits\n",
      "recall score:  0.9047698240885435\n",
      "parameters:  {'learning_rate': 1.0, 'n_estimators': 45}\n",
      "CPU times: total: 8.78 s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = 'recall'\n",
    "k_fold = 10\n",
    "param_grid = {\n",
    "             'learning_rate': [0.7,0.8,0.9,1.0],\n",
    "           'n_estimators': range(1,50,1)\n",
    "              }\n",
    "best_grid_search_model = GridSearchCV(estimator=AdaBoostClassifier(random_state=3),\n",
    "                                    scoring=score_measure, param_grid=param_grid, cv=k_fold, verbose=1,  n_jobs = -1)\n",
    "_ = best_grid_search_model.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', best_grid_search_model.best_score_)\n",
    "print('parameters: ', best_grid_search_model.best_params_)\n",
    "Best_recall_AdaBoost = best_grid_search_model.best_score_\n",
    "Recall_values.append(best_grid_search_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d2eb5-036a-4849-8c6e-c99067616652",
   "metadata": {},
   "source": [
    "#### The default adaboost model has a recall score of 0.9047698240885435. We customized adaboost using the two most critical parameters: n estimators and learning rate.\n",
    "- #### n_estimators : Number of trees we want to build before taking the maximum averages of predictions. Though, higher number of trees improves the performance, it will make the code to run slower. We have taken an ideal range of 1 to 50.\n",
    "- #### learning rate: learning rate represents each model's contribution to the weights and is set to 1 by default. When the learning rate is reduced, the weights are slightly increased or lowered, causing the model train to go slower (but sometimes resulting in better performance scores).\n",
    "#### After performing hyperparameter adjustment with a k-fold value of 10, we achieved the best model with parameters 'learning rate': 1.0, 'n estimators': 45, and recall of : 0.9047698240885435."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af5578-2fb9-4f5d-a16c-62af390f8270",
   "metadata": {},
   "source": [
    "# GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1970e7b1-672b-4295-845e-d676ae153609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters : Recall score:\n",
      "0.9001\n"
     ]
    }
   ],
   "source": [
    "#GradientBoosting\n",
    "gboost = GradientBoostingClassifier(random_state=3)\n",
    "_ = gboost.fit(train_X, train_y)\n",
    "y_pred = gboost.predict(test_X)\n",
    "print(f\"Using default parameters : Recall score:\\n{recall_score(test_y,y_pred):.4f}\")#Checking model Recall score.\n",
    "Recall_values.append(recall_score(test_y,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff5a6988-9a2e-49a9-94ed-3dfcb4b22984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "recall score:  0.9235100572034808\n",
      "parameters:  {'learning_rate': 1.5, 'max_depth': 2, 'n_estimators': 25}\n",
      "CPU times: total: 4.67 s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = 'recall'\n",
    "k_fold = 10\n",
    "param_grid ={ 'n_estimators' : [25, 50 ,75, 100, 200],\n",
    "              'learning_rate': [0.005 ,0.05, 0.5, 1.5,2],\n",
    "              'max_depth': [2, 4, 6, 8],\n",
    "              }\n",
    "best_grid_search_model = GridSearchCV(estimator=GradientBoostingClassifier(random_state=3), \n",
    "                                    scoring=score_measure, param_grid=param_grid, cv=k_fold, verbose=1,  n_jobs = -1)\n",
    "_ = best_grid_search_model.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', best_grid_search_model.best_score_)\n",
    "print('parameters: ', best_grid_search_model.best_params_)\n",
    "Best_recall_GB = best_grid_search_model.best_score_\n",
    "Recall_values.append(best_grid_search_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4b4dd-5689-41ec-86aa-a33fc816829d",
   "metadata": {},
   "source": [
    "#### Gradient boosting is a powerful technique for developing predictive models. It can benefit from regularization methods that penalize different parts of the algorithm and improve overall algorithm performance by reducing overfitting.\n",
    "#### Tunign n_estimators, Learning rate and max_depth:\n",
    "- #### The number of trees we add to the model is recorded by the variable n estimators. It can be costly computationally to process many trees. In general, n estimators should be changed to reflect changes in learning rate (a 10-fold drop in learning rate should correspond to an approximately 10-fold increase in n_estimators).\n",
    "- #### It can be said from the low learning_rate value of 0.05 that the n_estimators value is going to be high that seems to be the case as the best n_estimators ended up being : 100.\n",
    "- #### max_depth. This indicates how deep the built tree can be. The deeper the tree, the more splits it has and it captures more information about how the data. \n",
    "#### The Gradiant Boosting model tends to overfit the data and got a recall score of 0.9235100572034808. We have tuned gradiant boosting on the maximum depth that we allow the tree to grow, After performing hyperparameter tuning we got the best model at learning_rate': 1.5 , 'max_depth': 2, n_estimators': 25, with recall score: 0.9235100572034808."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf840a-a507-4f4e-b733-bd6bcc6cbe0c",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "347d1dec-1259-4e39-8476-f1ef6330de00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters : Recall score:\n",
      "0.9181\n"
     ]
    }
   ],
   "source": [
    "#XGBClassifier\n",
    "xgboost = XGBClassifier(random_state=1)\n",
    "_ = xgboost.fit(train_X, train_y)\n",
    "y_pred = xgboost.predict(test_X)\n",
    "print(f\"Using default parameters : Recall score:\\n{recall_score(test_y,y_pred):.4f}\")#Checking model Recall score.\n",
    "Recall_values.append(recall_score(test_y,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a2bf3cf-b75e-439e-9be2-82111e6561cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "recall score:  0.9141273960229961\n",
      "parameters:  {'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 80}\n",
      "CPU times: total: 7.89 s\n",
      "Wall time: 6min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = 'recall'\n",
    "k_fold = 10\n",
    "param_grid = {\n",
    "            \n",
    "    'n_estimators': [80, 100, 250, 500, 750],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "    'max_depth': [3, 6, 10, 15],\n",
    "            \n",
    "}\n",
    "\n",
    "           \n",
    "best_grid_search_model = GridSearchCV(estimator=XGBClassifier(random_state=1), \n",
    "                                    scoring=score_measure, param_grid=param_grid, cv=k_fold, verbose=1,  n_jobs = -1)\n",
    "_ = best_grid_search_model.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', best_grid_search_model.best_score_)\n",
    "print('parameters: ', best_grid_search_model.best_params_)\n",
    "Best_recall_XGB = best_grid_search_model.best_score_\n",
    "Recall_values.append(best_grid_search_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e9ec9-fb02-4dd8-9a74-c945b4211483",
   "metadata": {},
   "source": [
    "#### Extreme Gradient Boosting (XGBoost) is a distributed, scalable gradient-boosted decision tree (GBDT) machine learning framework. The top machine learning library for regression, classification, and ranking issues, it offers parallel tree boosting.\n",
    "#### Here we used max depth, learning_rate, and n_estimators as parameters. Max depth is the maximum depth of the tree. learning_rate parameter can be set to control the weighting of new trees added to the model. n estimators are the number of runs the model will try to learn. After hyper tuning, the best values for parameters are max depth: 6, learning rate: 0.2, and n estimators:80. Hence, we obtained the recall = 0.9141273960229961."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c40bdb3-06ef-4137-9d98-56a511b4b08b",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50880543-fec6-4342-8ee9-9b8d161593b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters : Recall score:\n",
      "0.8343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dsksr\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logClassifier=LogisticRegression(random_state=1)\n",
    "\n",
    "_ = logClassifier.fit(train_X,train_y)\n",
    "y_pred = logClassifier.predict(test_X)\n",
    "print(f\"Using default parameters : Recall score:\\n{recall_score(test_y,y_pred):.4f}\")#Checking model Recall score.\n",
    "Recall_values.append(recall_score(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9ce3a19-a504-44cc-ad22-b8d42fcc2327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall score:  0.8526071310805581\n",
      "parameters:  {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "CPU times: total: 625 ms\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = 'recall'\n",
    "k_fold = 10\n",
    "param_grid = { 'solver': ['liblinear'],\n",
    "                      'penalty': ['l1', 'l2',], # NOTE: 'elasticnet' is only supported by 'saga' solver\n",
    "                      'C': [100, 10, 1.0],\n",
    "                      'max_iter': [1000,2500, 5000] # number of iterations to converge (sometimes the default is not enough - and sometimes, it will never converge)\n",
    "                     }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_grid_search_model = GridSearchCV(estimator=LogisticRegression(random_state=1),\n",
    "                                    scoring=score_measure, param_grid=param_grid, \n",
    "                                    cv=k_fold, verbose=0,  n_jobs = -1,error_score='raise')\n",
    "_ = best_grid_search_model.fit(train_X, train_y)\n",
    "print(score_measure, 'score: ', best_grid_search_model.best_score_)\n",
    "print('parameters: ', best_grid_search_model.best_params_)\n",
    "Best_recall_logistic = best_grid_search_model.best_score_\n",
    "Recall_values.append(best_grid_search_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f42642-9668-4cef-a793-75155974b925",
   "metadata": {},
   "source": [
    "#### To find the best parameters, we have performed tuning for the following variables:\n",
    "- C - float, default=1.0 Inverse of regularization strength; must be a positive float.\n",
    "- penalty{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=l2\n",
    " \n",
    "            1. none: no penalty is added;\n",
    "            2. l2: add a L2 penalty term and it is the default choice;\n",
    "            3. l1: add a L1 penalty term;\n",
    "            4. elasticnet: both L1 and L2 penalty terms are added.\n",
    "- solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "\n",
    "            1. For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones;\n",
    "            2. For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss;\n",
    "            3. liblinear is limited to one-versus-rest schemes.\n",
    "        \n",
    "- max_iterint, default=100 ,Maximum number of iterations taken for the solvers to converge.\n",
    "\n",
    "#### After performing hyperparameter tuning when k-fold value is 10, we got the best model at 'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear' with recall score: 0.8526071310805581. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9cb0f74c-a612-4b36-a9a9-b6b9bdc44ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall scores...\n",
      "K-NN:                0.8111410589095497\n",
      "Decision Tree:       0.8927269859930325\n",
      "Random Forest:       0.9114500150535477\n",
      "Ada Boosted:         0.9047698240885435\n",
      "GradientBoosting:    0.9235100572034808\n",
      "XGBoost:             0.9141273960229961\n",
      "LogisticRegression:  0.8526071310805581\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall scores...\")\n",
    "print(f\"{'K-NN:':11}          {Best_recall_knn}\")\n",
    "print(f\"{'Decision Tree:':11}       {Best_recall_DT}\")\n",
    "print(f\"{'Random Forest:':11}       {Best_recall_RF}\")\n",
    "print(f\"{'Ada Boosted:':11}         {Best_recall_AdaBoost}\")\n",
    "print(f\"{'GradientBoosting:':11}    {Best_recall_GB}\")\n",
    "print(f\"{'XGBoost:':11}          {Best_recall_XGB}\")\n",
    "print(f\"{'LogisticRegression:':11}  {Best_recall_logistic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "220e589a-4522-4096-bb2f-d761b62806d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(list(zip(Algorithms, Recall_values)),\n",
    "               columns =['Algorithm', 'Recall'])\n",
    "score_df\n",
    "score_df['state']=['Default','After_tunning']*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0bb5c19-5de1-41d8-86b6-f4ce553477d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Recall</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.807866</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.811141</td>\n",
       "      <td>After_tunning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.883946</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.892727</td>\n",
       "      <td>After_tunning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.899420</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.911450</td>\n",
       "      <td>After_tunning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.891038</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.904770</td>\n",
       "      <td>After_tunning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.900064</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.923510</td>\n",
       "      <td>After_tunning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.918117</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.914127</td>\n",
       "      <td>After_tunning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.834300</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.852607</td>\n",
       "      <td>After_tunning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm    Recall          state\n",
       "0                  knn  0.807866        Default\n",
       "1                  knn  0.811141  After_tunning\n",
       "2         DecisionTree  0.883946        Default\n",
       "3         DecisionTree  0.892727  After_tunning\n",
       "4         RandomForest  0.899420        Default\n",
       "5         RandomForest  0.911450  After_tunning\n",
       "6   AdaBoostClassifier  0.891038        Default\n",
       "7   AdaBoostClassifier  0.904770  After_tunning\n",
       "8     GradientBoosting  0.900064        Default\n",
       "9     GradientBoosting  0.923510  After_tunning\n",
       "10       XGBClassifier  0.918117        Default\n",
       "11       XGBClassifier  0.914127  After_tunning\n",
       "12  LogisticRegression  0.834300        Default\n",
       "13  LogisticRegression  0.852607  After_tunning"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "098cc2f0-ea97-4f3c-86b5-30864babeda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "ax= sns.barplot(x = 'Algorithm',\n",
    "            y = 'Recall',\n",
    "            hue='state',\n",
    "            data = score_df,palette = \"Blues\",ci=None)\n",
    "for i in ax.containers:\n",
    "     ax.bar_label(i,fmt='%.3f%%')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae25638-8928-44ce-976a-40506f97bd9d",
   "metadata": {},
   "source": [
    "#### From the above table and the graph, we could come up with a conclusion and see the overall recall score that obtained after performing model evaluation and found that Gradient Boosting provides the optimal result of all with a recall score of 0.923510 after performing the hyperparameter tuning, followed by XGBoost classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f19459c-243b-4ef9-a999-99b9b6bf679f",
   "metadata": {},
   "source": [
    "# Business Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381780ca-d8e2-4a5e-8ef6-44883f35a3ee",
   "metadata": {},
   "source": [
    "- #### Since FP is preferable over FN here, we are focusing on the recall here. The recall is found to be improving by applying the Gradient boosting model and also provides an optimal output here.\n",
    "- #### We have noticed that after implementing K- Fold cross validation as well as Hyper parameter tuning, we have found that the recall of the models have been improved. \n",
    "- #### Overall, Gradient Boosting turned out to be better model.In conclusion, methods like K- Fold cross validation as well hyper parameter tuning, are extremely useful in improving the quality of outputs for binary classification model generation.\n",
    "- #### Gradient Boosting model captured most of the actual positives. This will help the bank to limit thier cost on the marketing and also generate their revenue better by targetting the relevant customers that will most probably take the term deposit policy rather than those who were not interested.\n",
    "- #### By looking at the past analysis on this problem, we could see that the previous noted people who have worked on this business problem has got a recall score of 79% after applying support vector machines algorithm. We have made it even more optimal comparitively and found the recall score higher than the previous work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
